{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Voice AI Intent Classification - Model Training\n",
        "\n",
        "This notebook trains the XLM-RoBERTa intent classifier with:\n",
        "1. Data loading and preprocessing\n",
        "2. Model initialization with Focal Loss\n",
        "3. Training loop with early stopping\n",
        "4. Model evaluation and saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load config\n",
        "with open('../configs/config.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "print(\"Configuration loaded:\")\n",
        "print(f\"  Model: {config['model']['name']}\")\n",
        "print(f\"  Batch size: {config['training']['batch_size']}\")\n",
        "print(f\"  Learning rate: {config['training']['learning_rate']}\")\n",
        "print(f\"  Epochs: {config['training']['num_epochs']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.data.dataset import load_data, create_dataloaders, IntentLabelEncoder\n",
        "from src.data.preprocessor import TextPreprocessor\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Initialize components\n",
        "tokenizer = AutoTokenizer.from_pretrained(config['model']['name'])\n",
        "preprocessor = TextPreprocessor()\n",
        "label_encoder = IntentLabelEncoder()\n",
        "\n",
        "print(f\"Number of intents: {label_encoder.num_labels}\")\n",
        "print(f\"Intents: {label_encoder.intents}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataloaders\n",
        "dataloaders, _ = create_dataloaders(\n",
        "    train_path='../' + config['data']['train_path'],\n",
        "    val_path='../' + config['data']['val_path'],\n",
        "    test_path='../' + config['data']['test_path'],\n",
        "    batch_size=config['training']['batch_size'],\n",
        "    max_length=config['model']['max_length'],\n",
        ")\n",
        "\n",
        "print(f\"Train batches: {len(dataloaders['train'])}\")\n",
        "print(f\"Val batches: {len(dataloaders['val'])}\")\n",
        "print(f\"Test batches: {len(dataloaders['test'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.models.intent_classifier import create_model\n",
        "\n",
        "# Create model with Focal Loss\n",
        "model = create_model(\n",
        "    model_name=config['model']['name'],\n",
        "    num_labels=config['model']['num_labels'],\n",
        "    dropout=config['model']['dropout'],\n",
        "    use_focal_loss=True,\n",
        "    focal_gamma=config['focal_loss']['gamma'],\n",
        ")\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Model: {config['model']['name']}\")\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.models.trainer import IntentTrainer, TrainingConfig\n",
        "\n",
        "# Create output directory\n",
        "output_dir = Path('../outputs/models')\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Training configuration\n",
        "training_config = TrainingConfig(\n",
        "    learning_rate=config['training']['learning_rate'],\n",
        "    weight_decay=config['training']['weight_decay'],\n",
        "    num_epochs=config['training']['num_epochs'],\n",
        "    warmup_ratio=config['training']['warmup_ratio'],\n",
        "    early_stopping_patience=config['training']['early_stopping_patience'],\n",
        "    output_dir=str(output_dir),\n",
        ")\n",
        "\n",
        "# Create trainer\n",
        "trainer = IntentTrainer(model, training_config, device=str(device))\n",
        "\n",
        "print(\"Trainer initialized!\")\n",
        "print(f\"Output directory: {output_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "# NOTE: This will take several minutes depending on your hardware\n",
        "# On CPU: ~5-10 min per epoch\n",
        "# On GPU: ~1-2 min per epoch\n",
        "\n",
        "history = trainer.train(\n",
        "    train_loader=dataloaders['train'],\n",
        "    val_loader=dataloaders['val'],\n",
        ")\n",
        "\n",
        "print(\"\\nTraining complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Plot Training History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Loss\n",
        "axes[0].plot(history['train_loss'], label='Train')\n",
        "axes[0].plot(history['val_loss'], label='Validation')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Training & Validation Loss')\n",
        "axes[0].legend()\n",
        "\n",
        "# F1 Score\n",
        "axes[1].plot(history['val_f1'], label='Val F1', color='green')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Macro F1')\n",
        "axes[1].set_title('Validation F1 Score')\n",
        "axes[1].legend()\n",
        "\n",
        "# Learning Rate\n",
        "axes[2].plot(history['learning_rate'], color='orange')\n",
        "axes[2].set_xlabel('Epoch')\n",
        "axes[2].set_ylabel('Learning Rate')\n",
        "axes[2].set_title('Learning Rate Schedule')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../outputs/plots/training_history.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nBest Val F1: {max(history['val_f1']):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Evaluate on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.evaluation.metrics import compute_metrics, EvaluationReport\n",
        "\n",
        "# Load best model\n",
        "trainer.load_checkpoint(output_dir / 'best_model.pt')\n",
        "\n",
        "# Evaluate on test set\n",
        "test_metrics = trainer.validate(dataloaders['test'])\n",
        "\n",
        "print(\"Test Set Results:\")\n",
        "print(f\"  Loss: {test_metrics['val_loss']:.4f}\")\n",
        "print(f\"  Accuracy: {test_metrics['val_accuracy']:.4f}\")\n",
        "print(f\"  Macro F1: {test_metrics['val_f1']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Full evaluation with detailed metrics\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "all_confidences = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in dataloaders['test']:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels']\n",
        "        \n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        probs = outputs['probabilities']\n",
        "        preds = probs.argmax(dim=-1)\n",
        "        confs = probs.max(dim=-1).values\n",
        "        \n",
        "        all_preds.extend(preds.cpu().tolist())\n",
        "        all_labels.extend(labels.tolist())\n",
        "        all_confidences.extend(confs.cpu().tolist())\n",
        "\n",
        "# Compute full metrics\n",
        "report = compute_metrics(\n",
        "    all_labels, all_preds, \n",
        "    intent_names=label_encoder.intents,\n",
        "    confidences=all_confidences\n",
        ")\n",
        "\n",
        "report.print_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Save Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Model saved at:\")\n",
        "print(f\"  Best model: {output_dir / 'best_model.pt'}\")\n",
        "print(f\"  Final model: {output_dir / 'final_model.pt'}\")\n",
        "print(f\"  Training history: {output_dir / 'training_history.json'}\")\n",
        "\n",
        "print(\"\\n Training notebook complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
